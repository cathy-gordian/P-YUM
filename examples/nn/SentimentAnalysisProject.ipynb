{"cells":[{"cell_type":"markdown","metadata":{"id":"o_R1RyZXnWun"},"source":["***Your Objective: Build a sentiment analysis model with BERT and the IMDB reviews dataset***\n","# ***Before beginning, please MAKE A COPY of this notebook and work on your own copy ***\n","Dataset: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n","Download this to your own computer\n","\n","**Before beginning, be sure to go to \"edit -> notebook settings -> hardware accelerator -> GPU\"** This will let you use google colabs GPU\n","\n","Please follow the structure laid out in the notebook and answer the questions\n","\n","Use whatever resources you need (google, stackoverflow, etc.) and feel free to copy paste and frankenstein code\n"]},{"cell_type":"markdown","metadata":{},"source":["Useful resources:\n","\n","https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n","\n","https://www.analyticsvidhya.com/blog/2021/12/fine-tune-bert-model-for-sentiment-analysis-in-google-colab/\n","\n","https://www.kaggle.com/code/prakharrathi25/sentiment-analysis-using-bert/notebook\n","\n","https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671"]},{"cell_type":"markdown","metadata":{"id":"wqEziKtkoD_3"},"source":["Use whatever libraries you want (though I would recommend pytorch if you have no preference because I like it more. Please avoid using ktrain for the deep learning bits). Some recommendations: tensorflow, pytorch, scikit learn, matplotlib, numpy, pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ySnGJU_CoxNd"},"outputs":[],"source":["# bert stuff (add additional imports here as well)\n","from transformers import BertTokenizer, BertConfig,AdamW, BertForSequenceClassification,get_linear_schedule_with_warmup, BertModel"]},{"cell_type":"markdown","metadata":{"id":"uE1EvdqIoxqv"},"source":["Read in your data and inspect it (what are the labels, check the balance, check training vs testing balance, remove garbage data, etc.)\n","\n","Good things to look up: Machine learning data pre-processing, feature engineering, cleaning data for training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xio700Mnm9ff"},"outputs":[],"source":["# UNCOMMENT THE CODE IF YOU ARE RUNNING THIS IN GOOGLE COLAB\n","# running this code will create a 'browse' button that allows you to upload the dataset to colab\n","# from google.colab import files\n","# uploaded = files.upload()"]},{"cell_type":"markdown","metadata":{},"source":["The below code cell uses the bert base cased pretrained model. What are some different ones and what might be the benefitial / detrimental parts of these other ones?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fzaPpaS6nWba"},"outputs":[],"source":["PRE_TRAINED_MODEL = 'bert_base_cased'\n","tokenizer = BertTokenizer.from_pretrained()"]},{"cell_type":"markdown","metadata":{"id":"RkX9aqGppiog"},"source":["Tokenize, encode, and truncate/pad the data. What do each of those terms mean? Why do we need to encode the text? Why do we need to truncate/pad the text? (Hint: BERT provides a tokenizer, encoder, and padder. It may be useful to look up bert_tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6BYQdyOZpwcd"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Xp7-Fw_zrY6W"},"source":["The tokenized, encoded, and truncated data should look like arrays of words where the words are replaced by ints and the rest are 0's based off your padding length. Ex: with a padding length of 10, the sentence \"I liked this movie\" might become [1, 3, 2, 4, 0, 0, 0, 0, 0, 0] (I liked this movie is represented by ints, and the rest are 0s to fit the padding length)\n","\n","BERT takes a fixed sequence length. Why might that be? What do you think a good sequence length is?"]},{"cell_type":"markdown","metadata":{"id":"IunejkgeqRl1"},"source":["Create your attention mask. What is the use of the attention mask for BERT? The attention mask should be an array of 1s and 0s."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mC7Lr_i7qZZz"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wtXakL_rqf6x"},"source":["Split your training/test/validation data and attention masks. What do these categories mean? Why do we need to separate our data into these categories?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJg_l1fiqzLC"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Kw5XuIC7r0Yi"},"source":["Your new and updated training, testing, and validation sets should be segmented forms of your data (ex. if you started with 2500 reviews, you might have 2000 as training, 250 as validation, 250 as testing)"]},{"cell_type":"markdown","metadata":{"id":"x0JhKpFWrb3I"},"source":["Do the necessary housekeeping to get all your data ready for evaluation (this will be different based off whatever deep learning library you are using)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Me8CqCtjrisR"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"137QovFUr_cz"},"source":["You will need to read in the data or store it in a specific manner to abide by the way in which the library you are using wants it"]},{"cell_type":"markdown","metadata":{"id":"vwd7Ibn5rqz_"},"source":["Build the model: Designate optimizers, layers, epochs, batch size, etc. Define each explicit parameter you designate (*check the next text cell). Give a very rough definition as to what each of these things mean (optimizers, layers, epochs, batch size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSTPFrttsAr4"},"outputs":[],"source":["model = BertModel.from_pretrained(PRE_TRAINED_MODEL)"]},{"cell_type":"markdown","metadata":{"id":"2wAdbak8sIsE"},"source":["Upon outputting the model, you should have a clear view of its components. It should match up with the parameters you set for it. Use your ML library to generate a summary of the model."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XU8IkjREsA0G"},"source":["Train! You might want to do this first and then go back and then answer the question that asks you to define the parameters so you don't have to sit in awkward silence during training (or have a nice conversation!)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRdMjK5usT5x"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7VlB4enmsUNg"},"source":["Validate! Make a confusion matrix. What is a confusion matrix and what is it showing?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UjJW_-5EsVsh"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"TuXZhCUOsUTu"},"source":["You should output a confusion matrix that has rows and cols that are labeled with positive/negative or whatever encoding you used"]},{"cell_type":"markdown","metadata":{"id":"D79JSwANsVzs"},"source":["Make some predictions on some sentences you come up with"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-sM5YIR9sp06"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"PTBLnMpgsi3F"},"source":["this should give you some sentiment polarity (a numerical score from 0 - 1)/ a binary positive or negative"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"SentimentAnalysisProject","provenance":[]},"kernelspec":{"display_name":"Python 3.7.9 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.9"},"vscode":{"interpreter":{"hash":"fc22371f3870926dbbcdf04161196d7334d8dc09d0b069ea32b843c425bf39e1"}}},"nbformat":4,"nbformat_minor":0}
